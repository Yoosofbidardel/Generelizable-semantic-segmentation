{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cityscapesscripts.download.downloader as cssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = (256, 128)\n",
    "\n",
    "dir_data = os.path.abspath(\"data\")\n",
    "\n",
    "dir_css = os.path.join(dir_data, \"cityscapes\")\n",
    "css_truth = os.path.join(dir_css, \"gtFine\")\n",
    "css_input = os.path.join(dir_css, \"leftImg8bit\")\n",
    "css_packages = ['gtFine_trainvaltest.zip', 'leftImg8bit_trainvaltest.zip']\n",
    "\n",
    "dir_truth_pp, dir_input_pp = ('labels', 'images')\n",
    "\n",
    "dir_bdd = os.path.join(dir_data, \"bdd100k\")\n",
    "dir_acdc = os.path.join(dir_data, \"acdc\")\n",
    "dir_map = os.path.join(dir_data, \"mapillary\")\n",
    "\n",
    "css_packages = ['gtFine_trainvaltest.zip', 'leftImg8bit_trainvaltest.zip']\n",
    "\n",
    "datasets_suffix = {\n",
    "    'css': ('_leftImg8bit.png', '_gtFine_color.png'),\n",
    "    'bdd': ('.png', '.png'),\n",
    "    'acdc': ('_rgb_anon.png', '_gt_labelColor.png'),\n",
    "    'map': ('.png', '.png')\n",
    "}\n",
    "\n",
    "css_truth_pp, css_input_pp = (f'{d}_{sample_size[0]}_{sample_size[1]}' for d in (os.path.join(dir_css, \"labels\"), os.path.join(dir_css, \"images\")))\n",
    "val_truth_pp, val_input_pp = (f'{d}_{sample_size[0]}_{sample_size[1]}' for d in (os.path.join(dir_css, \"labels_val\"), os.path.join(dir_css, \"images_val\")))\n",
    "\n",
    "bdd_truth_pp, bdd_input_pp = (f'{d}_{sample_size[0]}_{sample_size[1]}' for d in (os.path.join(dir_bdd, \"labels\"), os.path.join(dir_bdd, \"images\")))\n",
    "acdc_truth_pp, acdc_input_pp = (f'{d}_{sample_size[0]}_{sample_size[1]}' for d in (os.path.join(dir_acdc, \"labels\"), os.path.join(dir_acdc, \"images\")))\n",
    "map_truth_pp, map_input_pp = (f'{d}_{sample_size[0]}_{sample_size[1]}' for d in (os.path.join(dir_map, \"labels\"), os.path.join(dir_map, \"images\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    os.makedirs(dir_data, exist_ok=True)\n",
    "\n",
    "    if not os.path.isdir(dir_css):\n",
    "        download_css_data(css_packages)\n",
    "    \n",
    "    if not os.path.isdir(dir_bdd) and not os.path.isdir(dir_acdc) and not os.path.isdir(dir_map):\n",
    "        print('Downloading validation sets...')\n",
    "        download_val_data('https://drive.google.com/uc?export=download&id=1bqMZCM3EglnriBWnTm7CTLJkG2IRUa8E&confirm=t&uuid=71bddc44-83d6-4cb0-8924-7d1416a8274d&at=AKKF8vy8-rcAhelYzEd_NtzszJ4d:1684189570026')\n",
    "    else:\n",
    "        print('At least one of the validation sets still exist')\n",
    "\n",
    "def download_val_data(url: str):\n",
    "    # Create a temp directory to download into\n",
    "    with tempfile.TemporaryDirectory(dir=dir_data, prefix=\"download_\") as dir_temp:\n",
    "        print(f'Downloading: {url}')\n",
    "        zip_path = os.path.join(dir_temp, 'download.zip')\n",
    "        urlretrieve(url, zip_path, lambda n, size, total: sys.stdout.write(f'\\rProgress: {n*size/total*100:.2f} %'))\n",
    "        sys.stdout.write('\\n')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        print(f'Unpacking archive.')\n",
    "        shutil.unpack_archive(zip_path, dir_data)\n",
    "            \n",
    "        \n",
    "def download_css_data(package):\n",
    "    css_session = cssd.login()\n",
    "\n",
    "    os.makedirs(dir_css, exist_ok=True)\n",
    "\n",
    "    # Create a temp directory to download into\n",
    "    for dir, item in [(css_truth, [package[0]]), (css_input, [package[1]])]:\n",
    "        if not os.path.isdir(dir):\n",
    "            print(f'Directory does not exist: {dir}')\n",
    "            with tempfile.TemporaryDirectory(dir=dir_css, prefix=\"download_\") as dir_temp:\n",
    "                cssd.download_packages(session=css_session, package_names=item, destination_path=dir_temp, resume=False)\n",
    "\n",
    "                zip_path = os.path.join(dir_temp, item[0])\n",
    "\n",
    "                print(f'Unpacking archive.')\n",
    "                shutil.unpack_archive(zip_path, dir_css)\n",
    "        else:\n",
    "            print(f'Directory already downloaded: {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path_truth, path_input, path_truth_pp, path_input_pp, dataset: str):\n",
    "    input_suffix = datasets_suffix[dataset][0]\n",
    "    truth_suffix = datasets_suffix[dataset][1]\n",
    "    \n",
    "    # Run preprocessing\n",
    "    for dir_full, dir_pp in ((path_truth, path_truth_pp), (path_input, path_input_pp)):\n",
    "        # Check if the directory already exists\n",
    "        if os.path.isdir(dir_pp):\n",
    "            print(f'Preprocessed directory already exists: {dir_pp}')\n",
    "            continue\n",
    "\n",
    "        print(f'Preprocessing: {dir_full}')\n",
    "\n",
    "        # Walk though the directory and preprocess each file \n",
    "        for root,_,files in  os.walk( dir_full ):\n",
    "            if len(files) == 0:\n",
    "                continue\n",
    "            \n",
    "            sub_dir = root.replace(dir_full, \"\")\n",
    "            if sub_dir is not \"\":\n",
    "                print(f'Preprocessing sub-directory: {sub_dir}')\n",
    "\n",
    "            os.makedirs(dir_pp, exist_ok=True)\n",
    "\n",
    "            for f in files:\n",
    "                f_new = f.split(\".\")[0] + '.png'\n",
    "\n",
    "                if not (f_new.endswith(truth_suffix) or f_new.endswith(input_suffix)):\n",
    "                    continue\n",
    "                    \n",
    "                # Resize and save PNG image\n",
    "                path_original = os.path.join(root,f)\n",
    "                img_resized = Image.open(path_original).resize(sample_size, Image.NEAREST)\n",
    "                \n",
    "                # Normalize the image\n",
    "                #tensor_img = fn.to_tensor(img_resized).float()\n",
    "                #img_resized = fn.to_pil_image(fn.normalize(tensor_img))\n",
    "\n",
    "                #img_resized.save(path_original.replace(dir_full, dir_pp), 'png', quality=100)\n",
    "                img_resized.save(os.path.join(dir_pp, f_new), 'png', quality=100)\n",
    "\n",
    "    print(f'Preprocessing ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_dir = os.path.join(dir_data, 'mapillary')\n",
    "# images = []\n",
    "# for root,_,files in  os.walk(map_dir):\n",
    "#     sub_dir = root.replace(map_dir, \"\")\n",
    "#     if 'images_' not in sub_dir:\n",
    "#         if 'labels_' not in sub_dir:\n",
    "#             continue\n",
    "#     print(sub_dir)\n",
    "#     for f in files:\n",
    "#         if 'images_' in sub_dir:\n",
    "#             images.append(f)\n",
    "\n",
    "#         if 'labels_' in sub_dir:\n",
    "#             if 'p_abpafpngfUaYs4kCSF7w.png' in f:\n",
    "#                 print('fds') \n",
    "#             if f not in images:\n",
    "#                 print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "import re\n",
    "\n",
    "# Each class that we aim to detect is assigned a name, id and color.\n",
    "@dataclass\n",
    "class CityscapesClass:\n",
    "    name: str       # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                    # We use them to uniquely name a class\n",
    "\n",
    "    ID: int         # An integer ID that is associated with this label.\n",
    "                    # The IDs are used to represent the label in ground truth images\n",
    "                    # An ID of -1 means that this label does not have an ID and thus\n",
    "                    # is ignored when creating ground truth images (e.g. license plate).\n",
    "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                    # evaluation server.\n",
    "\n",
    "    trainId: int    # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                    # ground truth images with train IDs, using the tools provided in the\n",
    "                    # 'preparation' folder. However, make sure to validate or submit results\n",
    "                    # to our evaluation server using the regular IDs above!\n",
    "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                    # are mapped to the same class in the ground truth images. For the inverse\n",
    "                    # mapping, we use the label that is defined first in the list below.\n",
    "                    # For example, mapping all void-type classes to the same ID in training,\n",
    "                    # might make sense for some approaches.\n",
    "                    # Max value is 255!\n",
    "\n",
    "    category: str   # The name of the category that this label belongs to\n",
    "\n",
    "    categoryId: int # The ID of this category. Used to create ground truth images\n",
    "                    # on category level.\n",
    "\n",
    "    hasInstances: bool # Whether this label distinguishes between single instances or not\n",
    "\n",
    "    ignoreInEval: bool # Whether pixels having this class as ground truth label are ignored\n",
    "                       # during evaluations or not\n",
    "\n",
    "    color: Tuple[int, int, int]       # The color of this label\n",
    "\n",
    "\n",
    "# List of classes that we want to detect in the input\n",
    "classes = [\n",
    "    #                 name                     ID    trainId   category            catId     hasInstances   ignoreInEval   color\n",
    "    CityscapesClass(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    CityscapesClass(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    CityscapesClass(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    CityscapesClass(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    CityscapesClass(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "    CityscapesClass(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
    "    CityscapesClass(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
    "    CityscapesClass(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
    "    CityscapesClass(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
    "    CityscapesClass(  'parking'              ,  9 ,      255 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
    "    CityscapesClass(  'rail track'           , 10 ,      255 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
    "    CityscapesClass(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
    "    CityscapesClass(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
    "    CityscapesClass(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
    "    CityscapesClass(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
    "    CityscapesClass(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
    "    CityscapesClass(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
    "    CityscapesClass(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
    "    CityscapesClass(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (0  ,  0,  0) ),\n",
    "    CityscapesClass(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
    "    CityscapesClass(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
    "    CityscapesClass(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
    "    CityscapesClass(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
    "    CityscapesClass(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
    "    CityscapesClass(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
    "    CityscapesClass(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
    "    CityscapesClass(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
    "    CityscapesClass(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
    "    CityscapesClass(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
    "    CityscapesClass(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
    "    CityscapesClass(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
    "    CityscapesClass(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
    "    CityscapesClass(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
    "    CityscapesClass(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
    "    CityscapesClass(  'license plate'        , -1 ,      255 , 'vehicle'         , 7       , False        , True         , (0  ,0  ,  0) ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def from_filename(filename: str, dataset: str):\n",
    "        #match = re.match(r\"^(.*?)\\.(.*?)$\", filename, re.I)\n",
    "\n",
    "        #return (match.group(1), match.group(2))\n",
    "        filename = filename.replace(datasets_suffix[dataset][0], '')\n",
    "        filename = filename.replace(datasets_suffix[dataset][1], '')\n",
    "        #filename = filename.replace('.jpg', '')\n",
    "        if '.' in filename:\n",
    "            filename = filename.split(\".\")[0]+'.png'\n",
    "        return filename\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, dir_input: str, dir_truth: str, sample_size: Tuple[int,int], classes: List[str]):\n",
    "        super().__init__()\n",
    "\n",
    "        # These variables are also available as globals, but it is good practice to make classes\n",
    "        # not depend on global variables.\n",
    "        self.dir_input = dir_input\n",
    "        self.dir_truth = dir_truth\n",
    "        self.sample_size = sample_size\n",
    "        self.classes = classes\n",
    "        self.dataset = 'css'\n",
    "        \n",
    "        if 'acdc' in dir_input:\n",
    "            self.dataset = 'acdc'\n",
    "        elif 'bdd' in dir_input:\n",
    "            self.dataset = 'bdd'\n",
    "        elif 'map' in dir_input:\n",
    "            self.dataset = 'map'\n",
    "\n",
    "        # Walk through the inputs directory and add each file to our items list\n",
    "        self.items = []\n",
    "        for (_, _, filenames) in os.walk(self.dir_input):\n",
    "            self.items.extend([from_filename(f, self.dataset) for f in filenames])\n",
    "\n",
    "        # Sanity check: do the provided directories contain any samples?\n",
    "        assert len(self.items) > 0, f\"No items found in {self.dir_input}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, i: int) -> (torch.Tensor, torch.Tensor):\n",
    "        sample = self.items[i]\n",
    "\n",
    "        input = self.load_input(sample)\n",
    "        truth = self.load_truth(sample)\n",
    "\n",
    "        return self.transform(input, truth)\n",
    "\n",
    "    def load_input(self, sample: str) -> Image:\n",
    "        path = os.path.join(self.dir_input, f'{sample}{datasets_suffix[self.dataset][0]}')\n",
    "        return Image.open(path).convert(\"RGB\").resize(self.sample_size, Image.NEAREST)\n",
    "\n",
    "    def load_truth(self, sample: str) -> Image:\n",
    "        path = os.path.join(self.dir_truth, f'{sample}{datasets_suffix[self.dataset][1]}')\n",
    "        return Image.open(path).convert(\"RGB\").resize(self.sample_size, Image.NEAREST)\n",
    "\n",
    "    def transform(self, img: Image.Image, mask: Optional[Image.Image]) -> (torch.Tensor, torch.Tensor):\n",
    "        ## EXERCISE #####################################################################\n",
    "        #\n",
    "        # Data augmentation is a way to improve the accuracy of a model.\n",
    "        #\n",
    "        # Once you have a model that works, you can implement some data augmentation \n",
    "        # techniques here to further improve performance.\n",
    "        #\n",
    "        ##################################################################################\n",
    "\n",
    "        pass\n",
    "\n",
    "        ################################################################################# \n",
    "\n",
    "        # Convert the image to a tensor\n",
    "        img = TF.to_tensor(img)\n",
    "\n",
    "        # If no mask is provided, then return only the image\n",
    "        if mask is None:\n",
    "            return img, None\n",
    "\n",
    "        # Transform the mask from an image with RGB-colors to an 1-channel image with the index of the class as value\n",
    "        mask_size = [s for s in self.sample_size]\n",
    "        mask = torch.from_numpy(np.array(mask)).permute((2,0,1))\n",
    "        target = torch.zeros((mask_size[1], mask_size[0]), dtype=torch.uint8)\n",
    "        for i,c in enumerate(classes):\n",
    "            eq = mask[0].eq(c.color[0]) & mask[1].eq(c.color[1]) & mask[2].eq(c.color[2])\n",
    "            target[eq] = c.trainId    \n",
    "            \n",
    "        return img, target\n",
    "\n",
    "    def masks_to_indices(self, masks: torch.Tensor) -> torch.Tensor:\n",
    "        _, indices = masks.softmax(dim=1).max(dim=1)\n",
    "        return indices\n",
    "\n",
    "    def to_image(self, indices: torch.Tensor) -> Image.Image:\n",
    "        target = torch.zeros((3, indices.shape[0], indices.shape[1]),\n",
    "                             dtype=torch.uint8, device=indices.device, requires_grad=False)\n",
    "\n",
    "        for i, lbl in enumerate(self.classes):\n",
    "            eq = indices.eq(lbl.trainId)\n",
    "\n",
    "            target[0][eq] = lbl.color[0]\n",
    "            target[1][eq] = lbl.color[1]\n",
    "            target[2][eq] = lbl.color[2]\n",
    "\n",
    "        return TF.to_pil_image(target.cpu(), 'RGB')\n",
    "\n",
    "# Create one instance of the CityscapesDataset for each split type\n",
    "ds_split = {\n",
    "    'css': SegmentationDataset(css_input_pp, css_truth_pp, sample_size, classes),\n",
    "    'css_val': SegmentationDataset(val_input_pp, val_truth_pp, sample_size, classes),\n",
    "    'bdd': SegmentationDataset(bdd_input_pp, bdd_truth_pp, sample_size, classes),\n",
    "    'acdc': SegmentationDataset(acdc_input_pp, acdc_truth_pp, sample_size, classes),\n",
    "    'map': SegmentationDataset(map_input_pp, map_truth_pp, sample_size, classes),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from io import BytesIO\n",
    "from base64 import b64encode\n",
    "\n",
    "import random\n",
    "\n",
    "def display_samples():\n",
    "    # HTML templates for displaying random samples in a table\n",
    "    template_table = '<table><thead><tr><th>Subset</th><th>Amount</th><th>Size</th><th>Input sample</th><th>Truth sample</th></tr></thead><tbody>{0}</tbody></table>'\n",
    "    template_row = '<tr><td>{0}</td><td>{1}</td><td>{2}</td><td>{3}</td><td>{4}</td></tr>'\n",
    "    template_img = '<img src=\"data:image/png;base64,{0}\"/>'\n",
    "\n",
    "    # Display a random sample of each split of the dataset\n",
    "    rows = []\n",
    "    for name, ds_sub in ds_split.items():\n",
    "        # Draw a random sample from the dataset so that we can convert it back to an image\n",
    "        input, truth = random.choice(ds_sub)\n",
    "        #print(torch.unique(truth))\n",
    "\n",
    "        input = TF.to_pil_image(input)\n",
    "        truth = ds_sub.to_image(truth)\n",
    "\n",
    "        # Create a buffer to save each retrieved image into such that we can base64-encode it for diplay in our HTML table\n",
    "        with BytesIO() as buffer_input, BytesIO() as buffer_truth:\n",
    "            input.save(buffer_input, format='png')\n",
    "            truth.save(buffer_truth, format='png')\n",
    "\n",
    "            # Store one row of the dataset\n",
    "            images = [template_img.format(b64encode(b.getvalue()).decode('utf-8')) for b in (buffer_input, buffer_truth)]\n",
    "            rows.append(template_row.format(name, len(ds_sub), '&times;'.join([str(s) for s in input.size]), *images))\n",
    "\n",
    "    # Render HTML table\n",
    "    table = template_table.format(''.join(rows))\n",
    "    display(HTML(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_init():\n",
    "    download_data()\n",
    "\n",
    "    preprocess(os.path.join(css_truth, \"train\"), os.path.join(css_input, \"train\"), css_truth_pp, css_input_pp, 'css')\n",
    "    preprocess(os.path.join(css_truth, \"val\"), os.path.join(css_input, \"val\"), val_truth_pp, val_input_pp, 'css')\n",
    "    preprocess(os.path.join(dir_bdd, \"labels\"), os.path.join(dir_bdd, \"images\"), bdd_truth_pp, bdd_input_pp, 'bdd')\n",
    "    preprocess(os.path.join(dir_acdc, \"labels\"), os.path.join(dir_acdc, \"images\"), acdc_truth_pp, acdc_input_pp, 'acdc')\n",
    "    preprocess(os.path.join(dir_map, \"labels\"), os.path.join(dir_map, \"images\"), map_truth_pp, map_input_pp, 'map')\n",
    "\n",
    "    display_samples()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
